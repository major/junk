Applying Flash to a Parallel Fileystem in support of Openstack Environments
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**Abstract:**

Whilst a scalable parallel filesystem brings some interesting benefits in building a storage layer for Openstack environments, architecting Openstack on parallel filesystems is performed today largely in the absence of quality data. A single, highly scalable namespace for object, cinder, glance and mounted, shared filesystems is possible today with Spectrum Scale (previously GPFS) and can reduce the complexity of openstack environments and provide a useful path from traditional research environments into virtualised ones. However, today it is difficult, a-priori for an architect to understand the implications of running production services at scale on the IO loads placed upon the underlying filesystem and storage - in particular when using a parallel filesystem. Further to this, whether or not to deploy higher–cost flash tiers, and if so, how, and at what capacity complicates the architect's task. We provide benchmark data at scale to improve the current state of understanding.  


* **James Coomer** *(Dr James Coomer has held a career in High Performance Computing starting with a PhD in Theoretical Physics at Exeter University (UK), modelling material structures using high-performance computing techniques. James then spent over 10 years at Sun Microsystems and Dell in a wide range of High Performance Computing and Cloud roles from L3 support through consultancy, training, installation and pre-sales. James has specialised in the past in HPC schedulers, parallel programming and high-performance interconnects and filesystems before turning to focus on IO and storage in a move to DDN Storage in 2011. James now leads a team of technical staff in Europe.)*

* **Simon Thompson** *(Simon is the Research Computing Infrastructure Architect at the University of Birmingham. Working designing and building research data and computation systems. Recently much of Simon's time has been taken up designing and building OpenStack based private cloud systems including the pilot for the CLIMB project. CLIMB is an ambitious multi-University, multi-site deployment aimed at supporting microbial bioinformaticians and was built with Tom Connor (Cardiff University) and Nick Loman (University of Birmingham) and supported by the Medical Research Council. Simon enjoys challenging projects, and challenging the traditional approaches used which has led to the development of a private research cloud being deployed at University of Birmingham which includes being the first UK site to deploy Lenovo warm water cooling technology and even getting parts created to support the systems. He is also chair of the independent Spectrum Scale user group.)*
